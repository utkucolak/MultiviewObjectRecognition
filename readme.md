# Multiview Object Recognition

This project implements multiview object recognition using handcrafted feature detection and description methods inspired by SIFT and SURF. It matches a query image to one of many views across multiple object folders (e.g., COIL-100 format) using Harris keypoints, histogram-based descriptors, and a ratio-test matcher â€” all without OpenCV modules.

---

## âœ¨ Features

- ğŸ” **Custom Keypoint Detection** using Harris corner response
- ğŸ“ **SIFT-like Descriptor** using orientation histograms over local patches
- ğŸ¤ **Ratio-based Feature Matching** for robust correspondence
- âš¡ **Parallel Processing** for scalable multiview comparisons
- ğŸ“· **COIL-100-style Dataset** support

---

## ğŸ“ Folder Structure

```
MultiviewObjectRecognition/
â”œâ”€â”€ coil-100/              # (ignored) Full COIL-100 dataset
â”œâ”€â”€ dataset/               # (ignored) Subset used for testing
â”œâ”€â”€ features/              # Detector, Descriptor, Matcher modules
â”œâ”€â”€ utils/                 # I/O utilities for visualizing matches
â”œâ”€â”€ main.py                # Main matching pipeline
â”œâ”€â”€ matches_result.png     # Last matching result saved image
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ readme.md              # Project README
```

> âš ï¸ Note: `dataset/` and `coil-100/` are ignored via `.gitignore`.

---

## ğŸ› ï¸ Installation

```bash
git clone https://github.com/yourusername/MultiviewObjectRecognition.git
cd MultiviewObjectRecognition
pip install -r requirements.txt
```

> Requires Python 3.8+ and OpenCV + NumPy + tqdm

---

## ğŸš€ Usage

By default, `main.py` matches `dataset/obj_20/60.png` against all views of the first 20 objects:

```bash
python main.py
```

- Outputs `[DONE]` logs and `[RESULT] Best match` summary
- Saves the visualization as `matches_result.png`

You can change:
- `QUERY_IMG_PATH` in `main.py` to test a different query
- `MAX_OBJECTS` or `MAX_VIEWS_PER_OBJECT` to scale up

---

## ğŸ“Š Output Example

If match is successful, `matches_result.png` will show feature correspondences between query and best-matching view.

---

## âœ… How it Works

1. Detects Harris corners in query and dataset images
2. Computes SIFT-like descriptors over \( 8 	imes 8 \) patches (4Ã—4 cells, 8-bin histograms)
3. Matches descriptors using Lowe's ratio test
4. Picks the view with the highest number of good matches

---

## ğŸ¤ Contributing

If you'd like to help improve the project, feel free to fork and PR! Suggestions welcome for:
- Rotation-invariant descriptors
- Affine normalization
- ANN-based matchers

---

## ğŸ“¬ Contact

Created by **Mehmet Utku Ã‡olak**  
ğŸ“§ colakme19@itu.edu.tr
